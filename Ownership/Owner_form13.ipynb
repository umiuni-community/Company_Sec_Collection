{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30eb18a-0e9a-47cc-8440-697874c1fc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching filing folders for Moderna, Inc. (CIK: 1682852) from 2020 to 2021...\n",
      "Found 8 filing folders. Processing...\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698//privacy.htm (Status Code: 404)\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063//privacy.htm (Status Code: 404)\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//Archives/edgar/data/1682852/000119312521045149/d128674dsc13ga.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//Archives/edgar/data/1682852/000119312521045149/d128674dsc13ga.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149//privacy.htm (Status Code: 404)\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//Archives/edgar/data/1682852/000119312521040005/d127918dsc13ga.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//Archives/edgar/data/1682852/000119312521040005/d127918dsc13ga.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005//privacy.htm (Status Code: 404)\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//Archives/edgar/data/1682852/000110465921019771/tm215103d2_ex99.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//Archives/edgar/data/1682852/000110465921019771/tm215103d2_ex99.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//Archives/edgar/data/1682852/000110465921019771/tm215103d2_sc13g.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//Archives/edgar/data/1682852/000110465921019771/tm215103d2_sc13g.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771//privacy.htm (Status Code: 404)\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//Archives/edgar/data/1682852/000110465921018647/tv01407-modernainc.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//Archives/edgar/data/1682852/000110465921018647/tv01407-modernainc.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647//privacy.htm (Status Code: 404)\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874//privacy.htm (Status Code: 404)\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//index.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//index.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//search/search.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//search/search.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//investor/brokers.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//investor/brokers.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//edgar/quickedgar.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//edgar/quickedgar.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//about/forms/secforms.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//about/forms/secforms.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//answers/publicdocs.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//answers/publicdocs.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//about/upcoming-events.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//about/upcoming-events.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//eeoinfo/sec_access.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//eeoinfo/sec_access.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//about/offices/oacq.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//about/offices/oacq.htm (Status Code: 404)\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//privacy.htm\n",
      "Failed to download https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042//privacy.htm (Status Code: 404)\n",
      "No data to save.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "HEADERS = {\"User-Agent\": \"OwnershipDataScraper/1.0 (contact: example@example.com)\"}\n",
    "BASE_URL = \"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "DOWNLOAD_FOLDER = \"downloaded_htm_files\"\n",
    "\n",
    "# Ensure the download folder exists\n",
    "if not os.path.exists(DOWNLOAD_FOLDER):\n",
    "    os.makedirs(DOWNLOAD_FOLDER)\n",
    "\n",
    "# Step 1: Fetch Filing Folders\n",
    "def fetch_filing_folders(cik, start_year, end_year, form_types):\n",
    "    \"\"\"\n",
    "    Fetches filing folder URLs for a given CIK, year range, and form types.\n",
    "    \"\"\"\n",
    "    url = BASE_URL.format(cik=cik.zfill(10))\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch filings for CIK {cik}. Status code: {response.status_code}\")\n",
    "\n",
    "    data = response.json()\n",
    "    filings = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "    form_types_list = filings.get(\"form\", [])\n",
    "    accession_numbers = filings.get(\"accessionNumber\", [])\n",
    "    filing_dates = filings.get(\"filingDate\", [])\n",
    "\n",
    "    folders = []\n",
    "    for form, acc_no, filing_date in zip(form_types_list, accession_numbers, filing_dates):\n",
    "        if form in form_types:\n",
    "            year = int(filing_date.split(\"-\")[0])\n",
    "            if start_year <= year <= end_year:\n",
    "                formatted_acc_no = acc_no.replace(\"-\", \"\")\n",
    "                folder_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{formatted_acc_no}/\"\n",
    "                folders.append(folder_url)\n",
    "    return folders\n",
    "\n",
    "# Step 2: Find and Process All .htm Files\n",
    "def process_htm_files(folder_url):\n",
    "    \"\"\"\n",
    "    Extracts ownership data from all .htm files in a given folder URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(folder_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to access folder: {folder_url} (Status Code: {response.status_code})\")\n",
    "            return []\n",
    "\n",
    "        # Parse the folder listing\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        htm_files = [link['href'] for link in links if link['href'].endswith(\".htm\")]\n",
    "\n",
    "        ownership_data = []\n",
    "        for htm_file in htm_files:\n",
    "            htm_url = folder_url + htm_file\n",
    "            print(f\"Processing file: {htm_url}\")\n",
    "            data = extract_data_from_htm(htm_url)\n",
    "            if data:\n",
    "                ownership_data.extend(data)\n",
    "\n",
    "        return ownership_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {folder_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 3: Extract Data from .htm File\n",
    "def extract_data_from_htm(htm_url):\n",
    "    \"\"\"\n",
    "    Parses an .htm file to extract ownership data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(htm_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download {htm_url} (Status Code: {response.status_code})\")\n",
    "            return []\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        ownership_data = []\n",
    "\n",
    "        # Extract specific data fields (adjust selectors based on actual file structure)\n",
    "        tables = soup.find_all(\"table\")\n",
    "        for table in tables:\n",
    "            rows = table.find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_all(\"td\")\n",
    "                cols = [col.text.strip() for col in cols]\n",
    "                if len(cols) > 1:  # Adjust condition based on expected structure\n",
    "                    ownership_data.append({\n",
    "                        \"Owner Name\": cols[0],\n",
    "                        \"Shares Owned\": cols[1],\n",
    "                        \"Percent Owned\": cols[2] if len(cols) > 2 else \"N/A\",\n",
    "                        \"Source URL\": htm_url\n",
    "                    })\n",
    "\n",
    "        return ownership_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from {htm_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Save Data to CSV\n",
    "def save_to_csv(data, filename=\"ownership_data.csv\"):\n",
    "    \"\"\"\n",
    "    Save extracted data to a CSV file.\n",
    "    \"\"\"\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # User-defined parameters\n",
    "    company_name = \"Moderna, Inc.\"\n",
    "    cik = \"1682852\"\n",
    "    start_year = 2020\n",
    "    end_year = 2021\n",
    "    form_types = [\"SC 13G\", \"SC 13D\", \"SC 13G/A\", \"SC 13D/A\"]  # Add more if needed\n",
    "\n",
    "    print(f\"Fetching filing folders for {company_name} (CIK: {cik}) from {start_year} to {end_year}...\")\n",
    "    filing_folders = fetch_filing_folders(cik, start_year, end_year, form_types)\n",
    "\n",
    "    if filing_folders:\n",
    "        print(f\"Found {len(filing_folders)} filing folders. Processing...\")\n",
    "        all_ownership_data = []\n",
    "\n",
    "        for folder in filing_folders:\n",
    "            print(f\"Processing folder: {folder}\")\n",
    "            ownership_data = process_htm_files(folder)\n",
    "            if ownership_data:\n",
    "                all_ownership_data.extend(ownership_data)\n",
    "\n",
    "        # Save the data\n",
    "        save_to_csv(all_ownership_data)\n",
    "    else:\n",
    "        print(f\"No filing folders found for {company_name} in the specified period.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69509a7-d741-49dc-9593-df864b447ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching filing folders for Moderna, Inc. (CIK: 1682852) from 2020 to 2021...\n",
      "Found 8 filing folders. Processing...\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698/0000834237-21-008698.txt\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698/us60770k1079_071021.txt\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063/0001088875-21-000063.txt\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063/Moderna26022021.txt\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149/0001193125-21-045149.txt\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005/0001193125-21-040005.txt\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771/0001104659-21-019771.txt\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647/0001104659-21-018647.txt\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874/0000834237-21-006874.txt\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874/us60770k1079_020221.txt\n",
      "Processing folder: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042/\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042/0001088875-21-000042.txt\n",
      "Processing file: https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042/Moderna31122020.txt\n",
      "No data to save.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "HEADERS = {\"User-Agent\": \"OwnershipDataScraper/1.0 (contact: example@example.com)\"}\n",
    "BASE_URL = \"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "DOWNLOAD_FOLDER = \"downloaded_txt_files\"\n",
    "\n",
    "# Ensure the download folder exists\n",
    "if not os.path.exists(DOWNLOAD_FOLDER):\n",
    "    os.makedirs(DOWNLOAD_FOLDER)\n",
    "\n",
    "# Utility: Clean up file name\n",
    "def clean_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Cleans up the file name by removing any `/Archives/.../` prefix,\n",
    "    leaving only the file name itself.\n",
    "    \"\"\"\n",
    "    if \"/Archives/\" in file_name:\n",
    "        return file_name.split(\"/\")[-1]  # Keep only the last part (actual file name)\n",
    "    return file_name\n",
    "\n",
    "# Step 1: Fetch Filing Folders\n",
    "def fetch_filing_folders(cik, start_year, end_year, form_types):\n",
    "    \"\"\"\n",
    "    Fetches filing folder URLs for a given CIK, year range, and form types.\n",
    "    \"\"\"\n",
    "    url = BASE_URL.format(cik=cik.zfill(10))\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch filings for CIK {cik}. Status code: {response.status_code}\")\n",
    "\n",
    "    data = response.json()\n",
    "    filings = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "    form_types_list = filings.get(\"form\", [])\n",
    "    accession_numbers = filings.get(\"accessionNumber\", [])\n",
    "    filing_dates = filings.get(\"filingDate\", [])\n",
    "\n",
    "    folders = []\n",
    "    for form, acc_no, filing_date in zip(form_types_list, accession_numbers, filing_dates):\n",
    "        if form in form_types:\n",
    "            year = int(filing_date.split(\"-\")[0])\n",
    "            if start_year <= year <= end_year:\n",
    "                formatted_acc_no = acc_no.replace(\"-\", \"\")\n",
    "                folder_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{formatted_acc_no}/\"\n",
    "                folders.append(folder_url)\n",
    "    return folders\n",
    "\n",
    "# Step 2: Find and Process All .txt Files\n",
    "def process_txt_files(folder_url):\n",
    "    \"\"\"\n",
    "    Identifies and processes all .txt files in the given folder URL to extract ownership data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(folder_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to access folder: {folder_url} (Status Code: {response.status_code})\")\n",
    "            return []\n",
    "\n",
    "        # Parse the folder listing\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "        # Filter for .txt files\n",
    "        txt_files = [link['href'] for link in links if link['href'].endswith(\".txt\")]\n",
    "\n",
    "        ownership_data = []\n",
    "        for txt_file in txt_files:\n",
    "            # Clean the file name and construct the full URL\n",
    "            clean_name = clean_file_name(txt_file)\n",
    "            txt_url = f\"{folder_url.rstrip('/')}/{clean_name}\"\n",
    "            print(f\"Processing file: {txt_url}\")\n",
    "\n",
    "            # Validate file content before processing\n",
    "            if is_target_form(txt_url):\n",
    "                data = extract_data_from_txt(txt_url)\n",
    "                if data:\n",
    "                    ownership_data.extend(data)\n",
    "            else:\n",
    "                print(f\"Skipped file: {txt_url} (Not a target form)\")\n",
    "\n",
    "        return ownership_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {folder_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# New Helper Function: Validate if File Contains Target Form\n",
    "def is_target_form(file_url):\n",
    "    \"\"\"\n",
    "    Checks if the file contains the target form type (e.g., SC 13G, SC 13D).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(file_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download {file_url} for validation (Status Code: {response.status_code})\")\n",
    "            return False\n",
    "\n",
    "        content = response.text\n",
    "        # Check for target form types\n",
    "        target_forms = [\"SC 13G\", \"SC 13D\", \"SC 13G/A\", \"SC 13D/A\"]\n",
    "        return any(form in content for form in target_forms)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error validating file {file_url}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Step 3: Extract Data from .txt File\n",
    "def extract_data_from_txt(file_url):\n",
    "    \"\"\"\n",
    "    Parses a .txt file to extract ownership data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(file_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download {file_url} (Status Code: {response.status_code})\")\n",
    "            return []\n",
    "\n",
    "        content = response.text\n",
    "        ownership_data = []\n",
    "\n",
    "        # Split content into lines\n",
    "        lines = content.splitlines()\n",
    "        \n",
    "        # Variables to track extracted data\n",
    "        current_owner = None\n",
    "        current_shares = None\n",
    "        current_percent = None\n",
    "\n",
    "        # Iterate through lines to find relevant data\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Check for patterns in the file (adjust these based on actual file content)\n",
    "            if \"Name of Owner\" in line:\n",
    "                current_owner = line.split(\":\")[-1].strip()\n",
    "            elif \"Number of Shares\" in line or \"Shares Owned\" in line:\n",
    "                current_shares = line.split(\":\")[-1].strip()\n",
    "            elif \"Percent of Class\" in line or \"Ownership Percentage\" in line:\n",
    "                current_percent = line.split(\":\")[-1].strip()\n",
    "\n",
    "            # If all fields are found, add them to the data list\n",
    "            if current_owner and current_shares and current_percent:\n",
    "                ownership_data.append({\n",
    "                    \"Owner Name\": current_owner,\n",
    "                    \"Shares Owned\": current_shares,\n",
    "                    \"Percent Owned\": current_percent,\n",
    "                    \"Source URL\": file_url\n",
    "                })\n",
    "\n",
    "                # Reset variables for the next record\n",
    "                current_owner = None\n",
    "                current_shares = None\n",
    "                current_percent = None\n",
    "\n",
    "        # Return the extracted ownership data\n",
    "        return ownership_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from {file_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Save Data to CSV\n",
    "def save_to_csv(data, filename=\"ownership_data.csv\"):\n",
    "    \"\"\"\n",
    "    Save extracted data to a CSV file.\n",
    "    \"\"\"\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # User-defined parameters\n",
    "    company_name = \"Moderna, Inc.\"\n",
    "    cik = \"1682852\"\n",
    "    start_year = 2020\n",
    "    end_year = 2021\n",
    "    form_types = [\"SC 13G\", \"SC 13D\", \"SC 13G/A\", \"SC 13D/A\"]  # Add more if needed\n",
    "\n",
    "    print(f\"Fetching filing folders for {company_name} (CIK: {cik}) from {start_year} to {end_year}...\")\n",
    "    filing_folders = fetch_filing_folders(cik, start_year, end_year, form_types)\n",
    "\n",
    "    if filing_folders:\n",
    "        print(f\"Found {len(filing_folders)} filing folders. Processing...\")\n",
    "        all_ownership_data = []\n",
    "\n",
    "        for folder in filing_folders:\n",
    "            print(f\"Processing folder: {folder}\")\n",
    "            ownership_data = process_txt_files(folder)\n",
    "            if ownership_data:\n",
    "                all_ownership_data.extend(ownership_data)\n",
    "\n",
    "        # Save the data\n",
    "        save_to_csv(all_ownership_data)\n",
    "    else:\n",
    "        print(f\"No filing folders found for {company_name} in the specified period.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaedfa0f-43e1-4c1f-9cc8-de866b04d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching filing folders for Moderna, Inc. (CIK: 1682852) from 2020 to 2021...\n",
      "Found 8 filing folders. Extracting links...\n",
      "Extracted 12 links.\n",
      "Links saved to file_links.txt\n",
      "Processing links...\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698/0000834237-21-008698.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000083423721008698/us60770k1079_071021.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063/0001088875-21-000063.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000108887521000063/Moderna26022021.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000119312521045149/0001193125-21-045149.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000119312521040005/0001193125-21-040005.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000110465921019771/0001104659-21-019771.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000110465921018647/0001104659-21-018647.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874/0000834237-21-006874.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000083423721006874/us60770k1079_020221.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042/0001088875-21-000042.txt: name 're' is not defined\n",
      "Error extracting data from https://www.sec.gov/Archives/edgar/data/1682852/000108887521000042/Moderna31122020.txt: name 're' is not defined\n",
      "No data to save.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "HEADERS = {\"User-Agent\": \"OwnershipDataScraper/1.0 (contact: example@example.com)\"}\n",
    "BASE_URL = \"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "LINKS_FILE = \"file_links.txt\"\n",
    "OUTPUT_FILE = \"ownership_data.csv\"\n",
    "\n",
    "# Utility: Save links to a file\n",
    "def save_links(links, filename=LINKS_FILE):\n",
    "    \"\"\"\n",
    "    Save a list of links to a text file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"\\n\".join(links))\n",
    "    print(f\"Links saved to {filename}\")\n",
    "\n",
    "# Utility: Load links from a file\n",
    "def load_links(filename=LINKS_FILE):\n",
    "    \"\"\"\n",
    "    Load a list of links from a text file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            links = f.read().splitlines()\n",
    "        print(f\"Loaded {len(links)} links from {filename}\")\n",
    "        return links\n",
    "    return []\n",
    "\n",
    "# Utility: Clean up file name\n",
    "def clean_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Cleans up the file name by removing any `/Archives/.../` prefix,\n",
    "    leaving only the file name itself.\n",
    "    \"\"\"\n",
    "    if \"/Archives/\" in file_name:\n",
    "        return file_name.split(\"/\")[-1]  # Keep only the last part (actual file name)\n",
    "    return file_name\n",
    "\n",
    "# Step 1: Fetch Filing Folders\n",
    "def fetch_filing_folders(cik, start_year, end_year, form_types):\n",
    "    \"\"\"\n",
    "    Fetches filing folder URLs for a given CIK, year range, and form types.\n",
    "    \"\"\"\n",
    "    url = BASE_URL.format(cik=cik.zfill(10))\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch filings for CIK {cik}. Status code: {response.status_code}\")\n",
    "\n",
    "    data = response.json()\n",
    "    filings = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "    form_types_list = filings.get(\"form\", [])\n",
    "    accession_numbers = filings.get(\"accessionNumber\", [])\n",
    "    filing_dates = filings.get(\"filingDate\", [])\n",
    "\n",
    "    folders = []\n",
    "    for form, acc_no, filing_date in zip(form_types_list, accession_numbers, filing_dates):\n",
    "        if form in form_types:\n",
    "            year = int(filing_date.split(\"-\")[0])\n",
    "            if start_year <= year <= end_year:\n",
    "                formatted_acc_no = acc_no.replace(\"-\", \"\")\n",
    "                folder_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{formatted_acc_no}/\"\n",
    "                folders.append(folder_url)\n",
    "    return folders\n",
    "\n",
    "# Step 2: Extract All Links from Folders\n",
    "def extract_links_from_folders(filing_folders):\n",
    "    \"\"\"\n",
    "    Extract all .txt file links from the provided filing folders.\n",
    "    \"\"\"\n",
    "    all_links = []\n",
    "    for folder_url in filing_folders:\n",
    "        try:\n",
    "            response = requests.get(folder_url, headers=HEADERS)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to access folder: {folder_url} (Status Code: {response.status_code})\")\n",
    "                continue\n",
    "\n",
    "            # Parse the folder listing\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            links = soup.find_all(\"a\", href=True)\n",
    "\n",
    "            # Filter for .txt files and construct full URLs\n",
    "            for link in links:\n",
    "                if link['href'].endswith(\".txt\"):\n",
    "                    clean_name = clean_file_name(link['href'])\n",
    "                    txt_url = f\"{folder_url.rstrip('/')}/{clean_name}\"\n",
    "                    all_links.append(txt_url)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing folder {folder_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Extracted {len(all_links)} links.\")\n",
    "    return all_links\n",
    "\n",
    "# Step 3: Extract Data from a Single .txt File\n",
    "def extract_data_from_txt(file_url):\n",
    "    \"\"\"\n",
    "    Parses a .txt file to extract ownership data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(file_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download {file_url} (Status Code: {response.status_code})\")\n",
    "            return []\n",
    "\n",
    "        content = response.text\n",
    "        ownership_data = []\n",
    "\n",
    "        # Extract fields using regular expressions (adjust as needed)\n",
    "        name_match = re.search(r\"Name of Reporting Person.*?:\\s*(.+)\", content, re.IGNORECASE)\n",
    "        amount_match = re.search(r\"Amount beneficially owned.*?:\\s*([\\d,]+)\", content, re.IGNORECASE)\n",
    "        percent_match = re.search(r\"Percent of class.*?:\\s*([\\d.]+)%?\", content, re.IGNORECASE)\n",
    "\n",
    "        reporting_person = name_match.group(1).strip() if name_match else \"Not Found\"\n",
    "        beneficially_owned = amount_match.group(1).replace(\",\", \"\") if amount_match else \"Not Found\"\n",
    "        percent_of_class = percent_match.group(1) if percent_match else \"Not Found\"\n",
    "\n",
    "        ownership_data.append({\n",
    "            \"Name of Reporting Person\": reporting_person,\n",
    "            \"Amount Beneficially Owned\": beneficially_owned,\n",
    "            \"Percent of Class\": percent_of_class,\n",
    "            \"Source URL\": file_url\n",
    "        })\n",
    "\n",
    "        return ownership_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from {file_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Step 4: Save Data to CSV\n",
    "def save_to_csv(data, filename=OUTPUT_FILE):\n",
    "    \"\"\"\n",
    "    Save extracted data to a CSV file.\n",
    "    \"\"\"\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # User-defined parameters\n",
    "    company_name = \"Moderna, Inc.\"\n",
    "    cik = \"1682852\"\n",
    "    start_year = 2020\n",
    "    end_year = 2021\n",
    "    form_types = [\"SC 13G\", \"SC 13D\", \"SC 13G/A\", \"SC 13D/A\"]  # Add more if needed\n",
    "\n",
    "    # Load existing links if available\n",
    "    file_links = load_links()\n",
    "\n",
    "    if not file_links:\n",
    "        # Fetch filing folders and extract links if no saved links exist\n",
    "        print(f\"Fetching filing folders for {company_name} (CIK: {cik}) from {start_year} to {end_year}...\")\n",
    "        filing_folders = fetch_filing_folders(cik, start_year, end_year, form_types)\n",
    "\n",
    "        if filing_folders:\n",
    "            print(f\"Found {len(filing_folders)} filing folders. Extracting links...\")\n",
    "            file_links = extract_links_from_folders(filing_folders)\n",
    "            save_links(file_links)\n",
    "        else:\n",
    "            print(f\"No filing folders found for {company_name} in the specified period.\")\n",
    "            exit()\n",
    "\n",
    "    # Extract data from the saved links\n",
    "    print(\"Processing links...\")\n",
    "    all_ownership_data = []\n",
    "    for file_url in file_links:\n",
    "        ownership_data = extract_data_from_txt(file_url)\n",
    "        if ownership_data:\n",
    "            all_ownership_data.extend(ownership_data)\n",
    "\n",
    "    # Save the extracted data to a CSV\n",
    "    save_to_csv(all_ownership_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03a42d6f-2260-45aa-879b-73e09394d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 links from file_links.txt\n",
      "Processing links...\n",
      "Data saved to ownership_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Constants\n",
    "HEADERS = {\"User-Agent\": \"OwnershipDataScraper/1.0 (contact: example@example.com)\"}\n",
    "LINKS_FILE = \"file_links.txt\"\n",
    "OUTPUT_FILE = \"ownership_data.csv\"\n",
    "\n",
    "# Utility: Load links from a file\n",
    "def load_links(filename=LINKS_FILE):\n",
    "    \"\"\"\n",
    "    Load a list of links from a text file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            links = f.read().splitlines()\n",
    "        print(f\"Loaded {len(links)} links from {filename}\")\n",
    "        return links\n",
    "    return []\n",
    "\n",
    "# Utility: Save data to a CSV file\n",
    "def save_to_csv(data, filename=OUTPUT_FILE):\n",
    "    \"\"\"\n",
    "    Save extracted data to a CSV file.\n",
    "    \"\"\"\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Function to extract data from a single .txt file\n",
    "def extract_data_from_txt(file_url):\n",
    "    \"\"\"\n",
    "    Parses a .txt file to extract ownership data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(file_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download {file_url} (Status Code: {response.status_code})\")\n",
    "            return []\n",
    "\n",
    "        content = response.text\n",
    "        ownership_data = []\n",
    "\n",
    "        # Extract fields using regular expressions\n",
    "        name_match = re.search(r\"Name of Reporting Person.*?:\\s*(.+)\", content, re.IGNORECASE)\n",
    "        amount_match = re.search(r\"Amount beneficially owned.*?:\\s*([\\d,]+)\", content, re.IGNORECASE)\n",
    "        percent_match = re.search(r\"Percent of class.*?:\\s*([\\d.]+)%?\", content, re.IGNORECASE)\n",
    "\n",
    "        reporting_person = name_match.group(1).strip() if name_match else \"Not Found\"\n",
    "        beneficially_owned = amount_match.group(1).replace(\",\", \"\") if amount_match else \"Not Found\"\n",
    "        percent_of_class = percent_match.group(1) if percent_match else \"Not Found\"\n",
    "\n",
    "        ownership_data.append({\n",
    "            \"Name of Reporting Person\": reporting_person,\n",
    "            \"Amount Beneficially Owned\": beneficially_owned,\n",
    "            \"Percent of Class\": percent_of_class,\n",
    "            \"Source URL\": file_url\n",
    "        })\n",
    "\n",
    "        return ownership_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from {file_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load links from the saved file\n",
    "    file_links = load_links()\n",
    "\n",
    "    if not file_links:\n",
    "        print(f\"No links found in {LINKS_FILE}. Please extract the links first.\")\n",
    "        exit()\n",
    "\n",
    "    # Process the saved links\n",
    "    print(\"Processing links...\")\n",
    "    all_ownership_data = []\n",
    "    for file_url in file_links:\n",
    "        ownership_data = extract_data_from_txt(file_url)\n",
    "        if ownership_data:\n",
    "            all_ownership_data.extend(ownership_data)\n",
    "\n",
    "    # Save the extracted data to a CSV\n",
    "    save_to_csv(all_ownership_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8264b82-ab52-4945-9d90-2bf601b9e919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 links from file_links.txt\n",
      "Processing links...\n",
      "Data saved to ownership_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Constants\n",
    "HEADERS = {\"User-Agent\": \"OwnershipDataScraper/1.0 (contact: example@example.com)\"}\n",
    "LINKS_FILE = \"file_links.txt\"\n",
    "OUTPUT_FILE = \"ownership_data.csv\"\n",
    "\n",
    "# Utility: Load links from a file\n",
    "def load_links(filename=LINKS_FILE):\n",
    "    \"\"\"\n",
    "    Load a list of links from a text file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            links = f.read().splitlines()\n",
    "        print(f\"Loaded {len(links)} links from {filename}\")\n",
    "        return links\n",
    "    return []\n",
    "\n",
    "# Utility: Save data to a CSV file\n",
    "def save_to_csv(data, filename=OUTPUT_FILE):\n",
    "    \"\"\"\n",
    "    Save extracted data to a CSV file.\n",
    "    \"\"\"\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "# Function to extract data from a single .txt file\n",
    "def extract_data_from_txt(file_url):\n",
    "    \"\"\"\n",
    "    Parses a .txt file to extract ownership data, handling multi-line structures and variations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(file_url, headers=HEADERS)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download {file_url} (Status Code: {response.status_code})\")\n",
    "            return []\n",
    "\n",
    "        content = response.text\n",
    "\n",
    "        # Normalize the content (collapse multi-line sections and whitespace)\n",
    "        normalized_content = re.sub(r\"\\s+\", \" \", content)\n",
    "\n",
    "        ownership_data = []\n",
    "\n",
    "        # Extract 'Name of Reporting Person'\n",
    "        name_match = re.search(r\"(Name of Reporting Person|Name of Filer|Reporting Person).*?:\\s*(.+?)(?=\\s+(Item|Amount|Percent|$))\", normalized_content, re.IGNORECASE)\n",
    "        reporting_person = name_match.group(2).strip() if name_match else \"Not Found\"\n",
    "\n",
    "        # Extract 'Amount Beneficially Owned'\n",
    "        amount_match = re.search(r\"(Amount beneficially owned|Number of Shares).*?:\\s*([\\d,]+)\", normalized_content, re.IGNORECASE)\n",
    "        beneficially_owned = amount_match.group(2).replace(\",\", \"\") if amount_match else \"Not Found\"\n",
    "\n",
    "        # Extract 'Percent of Class'\n",
    "        percent_match = re.search(r\"(Percent of class|Percentage of Class).*?:\\s*([\\d.]+)%?\", normalized_content, re.IGNORECASE)\n",
    "        percent_of_class = percent_match.group(2) if percent_match else \"Not Found\"\n",
    "\n",
    "        # Extract 'Voting Power'\n",
    "        sole_voting_match = re.search(r\"(sole power to vote|sole voting power).*?:\\s*([\\d,]+)\", normalized_content, re.IGNORECASE)\n",
    "        shared_voting_match = re.search(r\"(shared power to vote|shared voting power).*?:\\s*([\\d,]+)\", normalized_content, re.IGNORECASE)\n",
    "        sole_dispose_match = re.search(r\"(sole power to dispose|sole dispositive power).*?:\\s*([\\d,]+)\", normalized_content, re.IGNORECASE)\n",
    "        shared_dispose_match = re.search(r\"(shared power to dispose|shared dispositive power).*?:\\s*([\\d,]+)\", normalized_content, re.IGNORECASE)\n",
    "\n",
    "        sole_voting_power = sole_voting_match.group(2).replace(\",\", \"\") if sole_voting_match else \"Not Found\"\n",
    "        shared_voting_power = shared_voting_match.group(2).replace(\",\", \"\") if shared_voting_match else \"Not Found\"\n",
    "        sole_dispose_power = sole_dispose_match.group(2).replace(\",\", \"\") if sole_dispose_match else \"Not Found\"\n",
    "        shared_dispose_power = shared_dispose_match.group(2).replace(\",\", \"\") if shared_dispose_match else \"Not Found\"\n",
    "\n",
    "        # Append the extracted data\n",
    "        ownership_data.append({\n",
    "            \"Name of Reporting Person\": reporting_person,\n",
    "            \"Amount Beneficially Owned\": beneficially_owned,\n",
    "            \"Percent of Class\": percent_of_class,\n",
    "            \"Sole Voting Power\": sole_voting_power,\n",
    "            \"Shared Voting Power\": shared_voting_power,\n",
    "            \"Sole Dispositive Power\": sole_dispose_power,\n",
    "            \"Shared Dispositive Power\": shared_dispose_power,\n",
    "            \"Source URL\": file_url\n",
    "        })\n",
    "\n",
    "        return ownership_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data from {file_url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # Load links from the saved file\n",
    "    file_links = load_links()\n",
    "\n",
    "    if not file_links:\n",
    "        print(f\"No links found in {LINKS_FILE}. Please extract the links first.\")\n",
    "        exit()\n",
    "\n",
    "    # Process the saved links\n",
    "    print(\"Processing links...\")\n",
    "    all_ownership_data = []\n",
    "    for file_url in file_links:\n",
    "        ownership_data = extract_data_from_txt(file_url)\n",
    "        if ownership_data:\n",
    "            all_ownership_data.extend(ownership_data)\n",
    "\n",
    "    # Save the extracted data to a CSV\n",
    "    save_to_csv(all_ownership_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e1054-871d-4706-abc7-39c540313ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
